#!/usr/bin/env python3
"""
ğŸ§ª INSTITUTIONAL REAL DATA ENGINE TEST
====================================
Comprehensive validation of the Phase 1 implementation

Tests:
1. Real data acquisition from multiple sources
2. Data validation and quality control
3. Cross-source validation and arbitrage detection
4. ML prediction system integration
5. Performance and reliability metrics
"""

import asyncio
import logging
import sys
import os
from datetime import datetime

# Add current directory to path
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

async def test_institutional_data_engine():
    """Comprehensive test of the institutional data engine"""
    print("ğŸ›ï¸ INSTITUTIONAL REAL DATA ENGINE - COMPREHENSIVE TESTING")
    print("=" * 70)
    
    try:
        # Import institutional modules
        from institutional_real_data_engine import (
            get_institutional_historical_data,
            get_institutional_real_time_price,
            get_data_quality_report,
            institutional_data_engine
        )
        
        from market_data_validator import (
            validate_market_data,
            get_data_validation_report
        )
        
        print("âœ… Successfully imported institutional modules")
        
        # Test 1: Real-time price acquisition
        print("\nğŸ”¥ TEST 1: Real-time Price Acquisition")
        print("-" * 40)
        
        real_time_price = get_institutional_real_time_price()
        if real_time_price:
            print(f"âœ… Real-time price: ${real_time_price:.2f}")
            print(f"ğŸ“Š Price range validation: {1800 <= real_time_price <= 4000}")
        else:
            print("âŒ Real-time price acquisition failed")
            
        # Test 2: Historical data acquisition
        print("\nğŸ“ˆ TEST 2: Historical Data Acquisition")
        print("-" * 40)
        
        timeframes = ['daily', 'hourly', '4h', '1h']
        data_results = {}
        
        for timeframe in timeframes:
            try:
                print(f"  Testing {timeframe} data...")
                df = get_institutional_historical_data(timeframe, 30, force_refresh=False)
                
                if df is not None and not df.empty:
                    data_results[timeframe] = {
                        'success': True,
                        'points': len(df),
                        'price_range': f"${df['Close'].min():.2f} - ${df['Close'].max():.2f}",
                        'latest_price': f"${df['Close'].iloc[-1]:.2f}"
                    }
                    print(f"    âœ… {timeframe}: {len(df)} points, latest: ${df['Close'].iloc[-1]:.2f}")
                else:
                    data_results[timeframe] = {'success': False, 'error': 'No data returned'}
                    print(f"    âŒ {timeframe}: No data returned")
                    
            except Exception as e:
                data_results[timeframe] = {'success': False, 'error': str(e)}
                print(f"    âŒ {timeframe}: Error - {e}")
        
        # Test 3: Data validation
        print("\nğŸ” TEST 3: Data Validation")
        print("-" * 40)
        
        for timeframe, result in data_results.items():
            if result.get('success'):
                try:
                    df = get_institutional_historical_data(timeframe, 30)
                    validation_result = validate_market_data(df, f"test_{timeframe}")
                    
                    print(f"  {timeframe} validation:")
                    print(f"    Valid: {validation_result.is_valid}")
                    print(f"    Confidence: {validation_result.confidence_score:.2%}")
                    print(f"    Issues: {len(validation_result.issues_detected)}")
                    
                except Exception as e:
                    print(f"    âŒ {timeframe} validation failed: {e}")
        
        # Test 4: Data quality report
        print("\nğŸ“‹ TEST 4: Data Quality Report")
        print("-" * 40)
        
        try:
            quality_report = get_data_quality_report('daily')
            print(f"âœ… Data quality: {quality_report.get('overall_health', 'Unknown')}")
            print(f"ğŸ“Š Source statistics available: {len(quality_report.get('source_statistics', []))}")
        except Exception as e:
            print(f"âŒ Quality report failed: {e}")
        
        # Test 5: ML integration
        print("\nğŸ¤– TEST 5: ML Integration")
        print("-" * 40)
        
        try:
            from ml_prediction_api import get_ml_predictions
            
            print("  Testing ML predictions with real data...")
            ml_result = await get_ml_predictions("XAUUSD")
            
            if ml_result.get('success'):
                predictions = ml_result.get('predictions', [])
                print(f"âœ… ML predictions generated: {len(predictions)} timeframes")
                print(f"ğŸ“Š Current price: ${ml_result.get('current_price', 0):.2f}")
                print(f"ğŸ›ï¸ Data quality: {ml_result.get('data_quality', 'Unknown')}")
                
                for pred in predictions[:3]:  # Show first 3
                    print(f"    {pred.get('timeframe', 'N/A')}: ${pred.get('predicted_price', 0):.2f} "
                          f"({pred.get('change_percent', 0):+.2f}%)")
            else:
                print(f"âŒ ML predictions failed: {ml_result.get('error', 'Unknown error')}")
                
        except ImportError as e:
            print(f"âš ï¸ ML integration test skipped: {str(e)}")
        except Exception as e:
            print(f"âŒ ML integration test failed: {str(e)}")
        
        # Test 6: Performance metrics
        print("\nâš¡ TEST 6: Performance Metrics")
        print("-" * 40)
        
        start_time = datetime.now()
        
        # Quick performance test
        for i in range(3):
            price = get_institutional_real_time_price()
            if price:
                print(f"  Test {i+1}: ${price:.2f}")
        
        elapsed = (datetime.now() - start_time).total_seconds()
        print(f"âœ… Performance: 3 price fetches in {elapsed:.2f}s ({elapsed/3:.3f}s avg)")
        
        # Summary
        print("\nğŸ¯ TEST SUMMARY")
        print("=" * 70)
        
        successful_timeframes = sum(1 for r in data_results.values() if r.get('success'))
        total_timeframes = len(data_results)
        
        print(f"ğŸ“Š Data acquisition: {successful_timeframes}/{total_timeframes} timeframes successful")
        print(f"ğŸ’° Real-time pricing: {'âœ… Working' if real_time_price else 'âŒ Failed'}")
        print(f"ğŸ” Data validation: {'âœ… Operational' if successful_timeframes > 0 else 'âŒ Failed'}")
        print(f"ğŸ›ï¸ Overall status: {'âœ… INSTITUTIONAL ENGINE OPERATIONAL' if successful_timeframes >= 2 else 'âš ï¸ PARTIAL FUNCTIONALITY'}")
        
        if successful_timeframes >= 2:
            print("\nğŸ‰ PHASE 1 IMPLEMENTATION: REAL DATA FOUNDATION REPLACEMENT - SUCCESS!")
            print("   âœ… Synthetic data generation completely replaced")
            print("   âœ… Multi-source real data acquisition operational")
            print("   âœ… Professional data validation implemented")
            print("   âœ… ML integration with real data functional")
        else:
            print("\nâš ï¸  PHASE 1 IMPLEMENTATION: NEEDS ATTENTION")
            print("   ğŸ“‹ Some data sources may need configuration")
            print("   ğŸ”§ Check API keys and network connectivity")
        
        print("\nğŸ›ï¸ Institutional Real Data Engine testing complete")
        
    except ImportError as e:
        print(f"âŒ Critical import error: {e}")
        print("ğŸ“‹ Ensure all required modules are properly installed")
    except Exception as e:
        print(f"âŒ Critical test failure: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    print("ğŸ§ª Starting Institutional Real Data Engine Test Suite...")
    asyncio.run(test_institutional_data_engine())
